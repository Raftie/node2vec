{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"/users/raf/googledrive/DOC/data/ccf_preprocessed.csv\", index_col=0, nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dff.iloc[:1000000]\n",
    "G_large = nx.Graph()\n",
    "G_large.add_nodes_from(df.TX_ID)\n",
    "G_large.add_nodes_from(df.CARD_PAN_ID.unique())\n",
    "G_large.add_nodes_from(df.TERM_MIDUID.unique())\n",
    "G_large.add_edges_from(zip(df.TX_ID, df.TERM_MIDUID))\n",
    "G_large.add_edges_from(zip(df.TX_ID, df.CARD_PAN_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_large = nx.convert_node_labels_to_integers(G_large, label_attribute='node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long does it take with Eliorc node2vec?\n",
    "n2v1 = Node2Vec(G_large, workers=8, quiet=False, p=2, q=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v2 = Node2Vec(G_large, workers=8, quiet=False, experimental=True, p=2, q=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probabilities': {0: array([0.15789474, 0.10526316, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  225: array([0.10526316, 0.15789474, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  272: array([0.10526316, 0.10526316, 0.15789474, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  339: array([0.10526316, 0.10526316, 0.10526316, 0.15789474, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  481: array([0.10526316, 0.10526316, 0.10526316, 0.10526316, 0.15789474,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  726: array([0.10526316, 0.10526316, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.15789474, 0.10526316, 0.10526316, 0.10526316]),\n",
       "  780: array([0.10526316, 0.10526316, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.15789474, 0.10526316, 0.10526316]),\n",
       "  822: array([0.10526316, 0.10526316, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.15789474, 0.10526316]),\n",
       "  900: array([0.10526316, 0.10526316, 0.10526316, 0.10526316, 0.10526316,\n",
       "         0.10526316, 0.10526316, 0.10526316, 0.15789474])},\n",
       " 'neighbors': [0, 225, 272, 339, 481, 726, 780, 822, 900],\n",
       " 'first_travel_key': array([0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v1.d_graph[1871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_travel_key': array([0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111]),\n",
       " 'probabilities': {0: array([0.04, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12]),\n",
       "  225: array([0.12, 0.04, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12]),\n",
       "  272: array([0.12, 0.12, 0.04, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12]),\n",
       "  339: array([0.12, 0.12, 0.12, 0.04, 0.12, 0.12, 0.12, 0.12, 0.12]),\n",
       "  481: array([0.12, 0.12, 0.12, 0.12, 0.04, 0.12, 0.12, 0.12, 0.12]),\n",
       "  726: array([0.12, 0.12, 0.12, 0.12, 0.12, 0.04, 0.12, 0.12, 0.12]),\n",
       "  780: array([0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.04, 0.12, 0.12]),\n",
       "  822: array([0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.04, 0.12]),\n",
       "  900: array([0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.04])},\n",
       " 'neighbors': [0, 225, 272, 339, 481, 726, 780, 822, 900]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v2.d_graph[1871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v1.d_graph[0]['first_travel_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v2.d_graph[0]['first_travel_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v1.d_graph[1871]['probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v2.d_graph[1871]['probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G_large)\n",
    "d_graph = dict()\n",
    "FIRST_TRAVEL_KEY = 'first_travel'\n",
    "PROBABILITIES_KEY = 'probs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity(A.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_travel_dict = defaultdict(dict)\n",
    "for node in tqdm(G_large.nodes()):\n",
    "    first_travel_dict[node][FIRST_TRAVEL_KEY] = (A[node, :] / np.sum(A[node, :])).data\n",
    "    #first_travel_dict[node][FIRST_TRAVEL_KEY].update({A[node, :].toarray()[0] / np.sum(A[node, :])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "q = 1\n",
    "prob_dict = defaultdict(dict)\n",
    "for current_node in tqdm(G_large.nodes()):\n",
    "    prob_dict[current_node][PROBABILITIES_KEY] = dict()\n",
    "    dict_to_add = prob_dict[current_node][PROBABILITIES_KEY]\n",
    "    for source in G_large.neighbors(current_node):\n",
    "        r = {source: (A[current_node, :] + ((1/p)-1)*(A[current_node, :].multiply(A[source, :]))).data}\n",
    "        dict_to_add.update(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_graph.update(first_travel_dict)\n",
    "for k,v in d_graph.items():\n",
    "    v.update(prob_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "q = 1\n",
    "d_graph = {}\n",
    "A = nx.adjacency_matrix(G_large)\n",
    "FIRST_TRAVEL_KEY = 'first_travel'\n",
    "PROBABILITIES_KEY = 'probs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_travel(node):\n",
    "    #ftd = defaultdict(dict)\n",
    "    #ftd[node][FIRST_TRAVEL_KEY] = (A[node, :] / np.sum(A[node, :])).data\n",
    "    ftd = (node, {FIRST_TRAVEL_KEY: (A[node, :] / np.sum(A[node, :])).data})\n",
    "    return ftd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(current_node):\n",
    "    pd = []\n",
    "    results = []\n",
    "    #pd = defaultdict(dict)\n",
    "    #pd[current_node][PROBABILITIES_KEY] = dict()\n",
    "    #dict_to_add = pd[current_node][PROBABILITIES_KEY]\n",
    "    for source in A[current_node, :].nonzero()[1]:\n",
    "        results.append((source, (A[current_node, :] + ((1/p)-1)*(A[current_node, :].multiply(A[source, :]))).data))\n",
    "        #dict_to_add.update(r)\n",
    "    \n",
    "    \n",
    "    pd = (current_node, {PROBABILITIES_KEY: dict(results)})\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joblib starts independent processes (or threads) without shared memory! Each process/thread receives \n",
    "a copy of the current program state. This is possible because the function does not update a shared variable. \n",
    "It only reads values from a copy of the adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is faster without shuffling the order in which the nodes are iterated over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_travels = Parallel(n_jobs=8, backend='multiprocessing')(delayed(get_first_travel)(node) for node in tqdm(G_large.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = Parallel(n_jobs=8)(delayed(get_probabilities)(node) for node in tqdm(G_large.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = dict(first_travels)\n",
    "first_travel_dict = dict(probs)\n",
    "d_graph.update(first_travel_dict)\n",
    "for k,v in d_graph.items():\n",
    "    v.update(prob_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "A = nx.adjacency_matrix(G)\n",
    "d_graph = dict()\n",
    "FIRST_TRAVEL_KEY = 'first_travel'\n",
    "PROBABILITIES_KEY = 'probs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the current nodes intstead of source nodes. \n",
    "\n",
    "first_travel_dict = {node: {FIRST_TRAVEL_KEY: A[node, :].toarray()[0] / np.sum(A[node, :])} for node in G.nodes()}\n",
    "prob_dict = {current_node: {PROBABILITIES_KEY: {source: (A[curn, :] + ((1/p)-1)*(A[curn, :].multiply(A[source, :]))).toarray() for source in G.neighbors(current_node)}} for current_node in G.nodes()}\n",
    "d_graph.update(first_travel_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in d_graph.items():\n",
    "    print(v)\n",
    "    v.update(prob_dict[k])\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curn = 2\n",
    "source = 0\n",
    "p = 2\n",
    "(A[curn, :] + ((1/p)-1)*(A[curn, :].multiply(A[source, :]))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{current_node: {PROBABILITIES_KEY: {source: (A[curn, :] + ((1/p)-1)*(A[curn, :].multiply(A[source, :]))).toarray() for source in G.neighbors(current_node)}} for current_node in G.nodes()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node2vec_develop",
   "language": "python",
   "name": "node2vec_develop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
